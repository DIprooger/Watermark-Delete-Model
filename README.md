
<details>
<summary>üá¨üáß English</summary>

# Watermark-Delete-Model

A neural network project for removing watermarks from images.

## üß† Description

This repository includes:

- `infer_one.py`: batch image cleaning using a trained Unet++ model.
- `dataset.py`: watermark augmentation using logos, with support for blend modes and random placement.
- `watermark-segmentation.ipynb`: notebook for training and testing.
- `my_image/`, `my_logo/`: folders for clean images and watermark logos.

## üöÄ How to use

1. Place input images into the `image_for_cleare/` folder.
2. Make sure `watermark_model.pth` is present in the project root.
3. Run:
   ```bash
   python infer_one.py
   ```
4. Cleaned images will be saved to the `output_cleaned/` folder.

## üß™ Training

The model is trained using synthetic data generated from clean images and watermark logos. The `Dataset` class applies realistic logo overlays with different blend modes and opacities.

## üß∞ Dependencies

Install dependencies:

```bash
pip install -r requirements.txt
```


# üìö How to Train the Watermark Removal Model

This guide explains how to train a neural network to remove watermarks using synthetic data generation.

---

## üß† Model

The model is based on:

- **Architecture**: Unet++
- **Encoder**: ResNet34
- **Library**: `segmentation_models_pytorch`

---

## üìÅ Folder Structure

```
.
‚îú‚îÄ‚îÄ my_image/             # Your clean images
‚îú‚îÄ‚îÄ my_logo/              # Watermark logos (PNG format with transparency)
‚îú‚îÄ‚îÄ dataset.py            # Synthetic watermark generator
‚îú‚îÄ‚îÄ watermark-segmentation.ipynb  # Training notebook
‚îú‚îÄ‚îÄ requirements.txt
```

---

## ‚öôÔ∏è Step-by-Step Training

1. **Install dependencies**

```bash
pip install -r requirements.txt
```

2. **Prepare training data**

- Place your clean images into the `my_image/` folder.
- Place watermark logos (transparent PNGs) into the `my_logo/` folder.

3. **Open notebook**

Run and modify the notebook:

```bash
jupyter notebook watermark-segmentation.ipynb
```

- It loads the synthetic dataset using `Dataset` class.
- Applies augmentation and trains the segmentation model.

4. **Save trained weights**

After training, export the model:

```python
torch.save({"model." + k: v for k, v in model.state_dict().items()}, "watermark_model.pth")
```

This file can be used for inference in `infer_one.py`.

---

## üîÅ Dataset Generation Logic

The dataset dynamically generates synthetic watermarked images and masks:
- Applies 1 to 5 logos per image.
- Random positions, scale, rotation.

</details>


<details>
<summary>üá∑üá∫ –†—É—Å—Å–∫–∏–π</summary>

# Watermark-Delete-Model

–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –ø—Ä–æ–µ–∫—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

## üß† –û–ø–∏—Å–∞–Ω–∏–µ

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –≤–∫–ª—é—á–∞–µ—Ç:

- `infer_one.py`: –ø–∞–∫–µ—Ç–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Unet++.
- `dataset.py`: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ—Ç–µ—Ä–º–∞—Ä–æ–∫ —Å –ª–æ–≥–æ—Ç–∏–ø–∞–º–∏, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–µ–∂–∏–º–æ–≤ –Ω–∞–ª–æ–∂–µ–Ω–∏—è.
- `watermark-segmentation.ipynb`: –Ω–æ—É—Ç–±—É–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
- `my_image/`, `my_logo/`: –ø–∞–ø–∫–∏ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –ª–æ–≥–æ—Ç–∏–ø–∞–º–∏.

## üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

1. –ü–æ–º–µ—Å—Ç–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫—É `image_for_cleare/`.
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª `watermark_model.pth` –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞.
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ:
   ```bash
   python infer_one.py
   ```
4. –û—á–∏—â–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—è–≤—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ `output_cleaned/`.

## üß™ –û–±—É—á–µ–Ω–∏–µ

–ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –≥–¥–µ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ª–æ–≥–æ—Ç–∏–ø—ã —Å —Ä–∞–∑–Ω–æ–π –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –∏ —Ä–µ–∂–∏–º–∞–º–∏ –Ω–∞–ª–æ–∂–µ–Ω–∏—è. –ö–ª–∞—Å—Å `Dataset` –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

## üß∞ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:

```bash
pip install -r requirements.txt
```


# üìö –ö–∞–∫ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —É–¥–∞–ª–µ–Ω–∏—è –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –æ–±—ä—è—Å–Ω—è–µ—Ç, –∫–∞–∫ –æ–±—É—á–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—É—é –º–æ–¥–µ–ª—å —É–¥–∞–ª–µ–Ω–∏—é –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

---

## üß† –ú–æ–¥–µ–ª—å

–ú–æ–¥–µ–ª—å –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞:

- **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ**: Unet++
- **–≠–Ω–∫–æ–¥–µ—Ä–µ**: ResNet34
- **–ë–∏–±–ª–∏–æ—Ç–µ–∫–µ**: `segmentation_models_pytorch`

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
.
‚îú‚îÄ‚îÄ my_image/             # –ò—Å—Ö–æ–¥–Ω—ã–µ (—á–∏—Å—Ç—ã–µ) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ my_logo/              # –õ–æ–≥–æ—Ç–∏–ø—ã –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ PNG —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é)
‚îú‚îÄ‚îÄ dataset.py            # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤
‚îú‚îÄ‚îÄ watermark-segmentation.ipynb  # –ù–æ—É—Ç–±—É–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ requirements.txt
```

---

## ‚öôÔ∏è –ü–æ—à–∞–≥–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ

1. **–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π**

```bash
pip install -r requirements.txt
```

2. **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**

- –ü–æ–º–µ—Å—Ç–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –≤ –ø–∞–ø–∫—É `my_image/`.
- –ü–æ–º–µ—Å—Ç–∏—Ç–µ –ª–æ–≥–æ—Ç–∏–ø—ã (—Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é) –≤ `my_logo/`.

3. **–û—Ç–∫—Ä–æ–π—Ç–µ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ—É—Ç–±—É–∫**

```bash
jupyter notebook watermark-segmentation.ipynb
```

- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–ª–∞—Å—Å `Dataset` –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
- –ü—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.

4. **–°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å**

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

```python
torch.save({"model." + k: v for k, v in model.state_dict().items()}, "watermark_model.pth")
```

–§–∞–π–ª `watermark_model.pth` –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ `infer_one.py`.

---

## üîÅ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç "–Ω–∞ –ª–µ—Ç—É":
- –û—Ç 1 –¥–æ 5 –ª–æ–≥–æ—Ç–∏–ø–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
- –°–ª—É—á–∞–π–Ω—ã–µ –ø–æ–∑–∏—Ü–∏—è, –º–∞—Å—à—Ç–∞–±, –ø–æ–≤–æ—Ä–æ—Ç.
- –†–µ–∂–∏–º—ã –Ω–∞–ª–æ–∂–µ–Ω–∏—è: `normal`, `multiply`, `overlay`.
- –°–æ–∑–¥–∞—ë—Ç—Å—è –±–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ –∑–æ–Ω –≤–æ–¥—è–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤.

–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Å–º. –≤ `dataset.py`.

---

## ‚úÖ –°–æ–≤–µ—Ç—ã

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –ª–æ–≥–æ—Ç–∏–ø—ã.
- –î–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –≥—Ä–∞–Ω–∏—Ü –ª–æ–≥–æ—Ç–∏–ø–æ–≤ –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å `dilate` –≤ –∫–ª–∞—Å—Å–µ `Dataset`.
- –î–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ IoU –∏–ª–∏ Dice.
- 
</details>
